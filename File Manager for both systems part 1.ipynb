{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03857469-18af-4df7-869c-0c014cbddf88",
   "metadata": {},
   "source": [
    "# For MSD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125dfbf5-4b9e-4443-91ce-aea38f075157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88630e2a-fb86-4756-89d0-68ec9d307c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/Users/vivekrambha/Documents/QMUL Slides and Notes/Music recommendation system/millionsongsubset/MillionSongSubset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83ed719-9915-4ab6-a8be-3864afab7ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_song_features(file_path):\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        features = {\n",
    "            'segments_pitches': f['/analysis/segments_pitches'][:].tolist()\n",
    "        }\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06e2854-a110-4c5e-8475-957076c90ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_metadata(file_path):\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        artist_name = f['/metadata/songs'][0]['artist_name'].decode('utf-8')\n",
    "        song_title = f['/metadata/songs'][0]['title'].decode('utf-8')\n",
    "        album_name = f['/metadata/songs'][0]['release'].decode('utf-8')\n",
    "    return artist_name, song_title, album_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a7c385-143d-462d-8259-5a010ef17897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_features(dataset_path):\n",
    "    data = []\n",
    "    for root, dirs, files in os.walk(dataset_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.h5'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    features = load_song_features(file_path)\n",
    "                    artist_name, song_title, album_name = load_metadata(file_path)\n",
    "                    song_id = os.path.splitext(file)[0]  # Using file name as song ID\n",
    "                    data.append({\n",
    "                        'song_id': song_id,\n",
    "                        'segments_pitches': json.dumps(features['segments_pitches']),\n",
    "                        'artist_name': artist_name,\n",
    "                        'song_title': song_title,\n",
    "                        'album_name': album_name\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing file {file_path}: {e}\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e43ecb-364e-4ce1-84a0-ff8bdbb7450c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_song_data = extract_all_features(dataset_path)\n",
    "\n",
    "df = pd.DataFrame(all_song_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2f59a3-bf93-4a97-a30f-b0286aab1481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to CSV\n",
    "df.to_csv('song_features.csv', index=False)\n",
    "print(\"Features and metadata saved to song_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae79cb5-8e1d-44ff-b3df-b7c932a7a35b",
   "metadata": {},
   "source": [
    "# For MXM dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763763e0-77f6-4a79-b5da-300c18668f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Thierry Bertin-Mahieux (2011) Columbia University\n",
    "tb2332@columbia.edu\n",
    "\n",
    "This code puts the musiXmatch dataset (format: 2 text files)\n",
    "into a SQLite database for ease of use.\n",
    "\n",
    "This is part of the Million Song Dataset project from\n",
    "LabROSA (Columbia University) and The Echo Nest.\n",
    "http://labrosa.ee.columbia.edu/millionsong/\n",
    "\n",
    "Copyright 2011, Thierry Bertin-Mahieux\n",
    "\n",
    "This program is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "def encode_string(s):\n",
    "    \"\"\"\n",
    "    Simple utility function to make sure a string is proper\n",
    "    to be used in a SQLite query\n",
    "    (different than posgtresql, no N to specify unicode)\n",
    "    EXAMPLE:\n",
    "      That's my boy! -> 'That''s my boy!'\n",
    "    \"\"\"\n",
    "    return \"'\" + s.replace(\"'\", \"''\") + \"'\"\n",
    "\n",
    "\n",
    "def die_with_usage():\n",
    "    \"\"\" HELP MENU \"\"\"\n",
    "    print('mxm_dataset_to_db.py')\n",
    "    print('   by T. Bertin-Mahieux (2011) Columbia University')\n",
    "    print('      tb2332@columbia.edu')\n",
    "    print('This code puts the musiXmatch dataset into an SQLite database.')\n",
    "    print('')\n",
    "    print('USAGE:')\n",
    "    print('  ./mxm_dataset_to_db.py <train> <test> <output.db>')\n",
    "    print('PARAMS:')\n",
    "    print('      <train>  - mXm dataset text train file')\n",
    "    print('       <test>  - mXm dataset text test file')\n",
    "    print('  <output.db>  - SQLite database to create')\n",
    "    sys.exit(0)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # help menu\n",
    "    if len(sys.argv) < 4:\n",
    "        die_with_usage()\n",
    "\n",
    "    # params\n",
    "    trainf = sys.argv[1]\n",
    "    testf = sys.argv[2]\n",
    "    outputf = sys.argv[3]\n",
    "\n",
    "    # sanity checks\n",
    "    if not os.path.isfile(trainf):\n",
    "        print(f'ERROR: {trainf} does not exist.')\n",
    "        sys.exit(0)\n",
    "    if not os.path.isfile(testf):\n",
    "        print(f'ERROR: {testf} does not exist.')\n",
    "        sys.exit(0)\n",
    "    if os.path.exists(outputf):\n",
    "        print(f'ERROR: {outputf} already exists.')\n",
    "        sys.exit(0)\n",
    "\n",
    "    # open output SQLite file\n",
    "    conn = sqlite3.connect(outputf)\n",
    "\n",
    "    # create tables -> words and lyrics\n",
    "    q = \"CREATE TABLE words (word TEXT PRIMARY KEY)\"\n",
    "    conn.execute(q)\n",
    "    q = \"\"\"\n",
    "    CREATE TABLE lyrics (\n",
    "        track_id TEXT,\n",
    "        mxm_tid INT,\n",
    "        word TEXT,\n",
    "        count INT,\n",
    "        is_test INT,\n",
    "        FOREIGN KEY(word) REFERENCES words(word)\n",
    "    )\n",
    "    \"\"\"\n",
    "    conn.execute(q)\n",
    "\n",
    "    # get words, put them in the words table\n",
    "    with open(trainf, 'r') as f:\n",
    "        for line in f:\n",
    "            if line == '':\n",
    "                continue\n",
    "            if line[0] == '%':\n",
    "                topwords = line.strip()[1:].split(',')\n",
    "                break\n",
    "    for w in topwords:\n",
    "        q = f\"INSERT INTO words VALUES({encode_string(w)})\"\n",
    "        conn.execute(q)\n",
    "    conn.commit()\n",
    "    # sanity check, make sure the words were entered according\n",
    "    # to popularity, most popular word should have ROWID 1\n",
    "    q = \"SELECT ROWID, word FROM words ORDER BY ROWID\"\n",
    "    res = conn.execute(q)\n",
    "    tmpwords = res.fetchall()\n",
    "    assert len(tmpwords) == len(topwords), 'Number of words issue.'\n",
    "    for k in range(len(tmpwords)):\n",
    "        assert tmpwords[k][0] == k + 1, 'ROWID issue.'\n",
    "        assert tmpwords[k][1] == topwords[k], 'ROWID issue.'\n",
    "    print(\"'words' table filled, checked.\")\n",
    "\n",
    "    # we put the train data in the dataset\n",
    "    with open(trainf, 'r') as f:\n",
    "        cnt_lines = 0\n",
    "        for line in f:\n",
    "            if line == '' or line.strip() == '':\n",
    "                continue\n",
    "            if line[0] in ('#', '%'):\n",
    "                continue\n",
    "            lineparts = line.strip().split(',')\n",
    "            tid = lineparts[0]\n",
    "            mxm_tid = lineparts[1]\n",
    "            for wordcnt in lineparts[2:]:\n",
    "                wordid, cnt = wordcnt.split(':')\n",
    "                q = f\"\"\"\n",
    "                INSERT INTO lyrics\n",
    "                SELECT '{tid}', {mxm_tid}, words.word, {cnt}, 0\n",
    "                FROM words WHERE words.ROWID={wordid}\n",
    "                \"\"\"\n",
    "                conn.execute(q)\n",
    "            # verbose\n",
    "            cnt_lines += 1\n",
    "            if cnt_lines % 15000 == 0:\n",
    "                print(f'Done with {cnt_lines} train tracks.')\n",
    "                conn.commit()\n",
    "    conn.commit()\n",
    "    print('Train lyrics added.')\n",
    "\n",
    "    # we put the test data in the dataset\n",
    "    # only difference from train: is_test is now 1\n",
    "    with open(testf, 'r') as f:\n",
    "        cnt_lines = 0\n",
    "        for line in f:\n",
    "            if line == '' or line.strip() == '':\n",
    "                continue\n",
    "            if line[0] in ('#', '%'):\n",
    "                continue\n",
    "            lineparts = line.strip().split(',')\n",
    "            tid = lineparts[0]\n",
    "            mxm_tid = lineparts[1]\n",
    "            for wordcnt in lineparts[2:]:\n",
    "                wordid, cnt = wordcnt.split(':')\n",
    "                q = f\"\"\"\n",
    "                INSERT INTO lyrics\n",
    "                SELECT '{tid}', {mxm_tid}, words.word, {cnt}, 1\n",
    "                FROM words WHERE words.ROWID={wordid}\n",
    "                \"\"\"\n",
    "                conn.execute(q)\n",
    "            # verbose\n",
    "            cnt_lines += 1\n",
    "            if cnt_lines % 15000 == 0:\n",
    "                print(f'Done with {cnt_lines} test tracks.')\n",
    "                conn.commit()\n",
    "    conn.commit()\n",
    "    print('Test lyrics added.')\n",
    "\n",
    "    # create indices\n",
    "    q = \"CREATE INDEX idx_lyrics1 ON lyrics (track_id)\"\n",
    "    conn.execute(q)\n",
    "    q = \"CREATE INDEX idx_lyrics2 ON lyrics (mxm_tid)\"\n",
    "    conn.execute(q)\n",
    "    q = \"CREATE INDEX idx_lyrics3 ON lyrics (word)\"\n",
    "    conn.execute(q)\n",
    "    q = \"CREATE INDEX idx_lyrics4 ON lyrics (count)\"\n",
    "    conn.execute(q)\n",
    "    q = \"CREATE INDEX idx_lyrics5 ON lyrics (is_test)\"\n",
    "    conn.execute(q)\n",
    "    conn.commit()\n",
    "    print('Indices created.')\n",
    "\n",
    "    # close output SQLite connection\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94296228-e546-481a-a0d4-41933eaa9e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_string(s):\n",
    "    \"\"\"\n",
    "    Simple utility function to make sure a string is proper\n",
    "    to be used in a SQLite query\n",
    "    (different than posgtresql, no N to specify unicode)\n",
    "    EXAMPLE:\n",
    "      That's my boy! -> 'That''s my boy!'\n",
    "    \"\"\"\n",
    "    return \"'\" + s.replace(\"'\", \"''\") + \"'\"\n",
    "\n",
    "def die_with_usage():\n",
    "    \"\"\" HELP MENU \"\"\"\n",
    "    print('mxm_dataset_to_db.py')\n",
    "    print('   by T. Bertin-Mahieux (2011) Columbia University')\n",
    "    print('      tb2332@columbia.edu')\n",
    "    print('This code puts the musiXmatch dataset into an SQLite database.')\n",
    "    print('')\n",
    "    print('USAGE:')\n",
    "    print('  ./mxm_dataset_to_db.py <train> <test> <output.db>')\n",
    "    print('PARAMS:')\n",
    "    print('      <train>  - mXm dataset text train file')\n",
    "    print('       <test>  - mXm dataset text test file')\n",
    "    print('  <output.db>  - SQLite database to create')\n",
    "    sys.exit(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b539259-80d9-4460-8b48-e32f25a597ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainf = \"/Users/vivekrambha/Documents/QMUL Slides and Notes/Music recommendation system/mxm_dataset_train.txt\"\n",
    "testf = \"/Users/vivekrambha/Documents/QMUL Slides and Notes/Music recommendation system/mxm_dataset_test.txt\"\n",
    "outputf = \"music_recommendation.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685f48d5-8fdc-4ebc-967f-04f1ebd46550",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(trainf):\n",
    "    print(f'ERROR: {trainf} does not exist.')\n",
    "    die_with_usage()\n",
    "if not os.path.isfile(testf):\n",
    "    print(f'ERROR: {testf} does not exist.')\n",
    "    die_with_usage()\n",
    "if os.path.exists(outputf):\n",
    "    print(f'ERROR: {outputf} already exists.')\n",
    "    die_with_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce03714-6510-4248-bd9f-44fe39ae638b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(outputf)\n",
    "\n",
    "q = \"CREATE TABLE words (word TEXT PRIMARY KEY)\"\n",
    "conn.execute(q)\n",
    "q = \"\"\"\n",
    "CREATE TABLE lyrics (\n",
    "    track_id TEXT,\n",
    "    mxm_tid INT,\n",
    "    word TEXT,\n",
    "    count INT,\n",
    "    is_test INT,\n",
    "    FOREIGN KEY(word) REFERENCES words(word)\n",
    ")\n",
    "\"\"\"\n",
    "conn.execute(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e280965-c3fb-426c-bb79-a0c8ef06356f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(trainf, 'r') as f:\n",
    "    for line in f:\n",
    "        if line == '':\n",
    "            continue\n",
    "        if line[0] == '%':\n",
    "            topwords = line.strip()[1:].split(',')\n",
    "            break\n",
    "for w in topwords:\n",
    "    q = f\"INSERT INTO words VALUES({encode_string(w)})\"\n",
    "    conn.execute(q)\n",
    "conn.commit()\n",
    "\n",
    "q = \"SELECT ROWID, word FROM words ORDER BY ROWID\"\n",
    "res = conn.execute(q)\n",
    "tmpwords = res.fetchall()\n",
    "assert len(tmpwords) == len(topwords), 'Number of words issue.'\n",
    "for k in range(len(tmpwords)):\n",
    "    assert tmpwords[k][0] == k + 1, 'ROWID issue.'\n",
    "    assert tmpwords[k][1] == topwords[k], 'ROWID issue.'\n",
    "print(\"'words' table filled, checked.\")\n",
    "\n",
    "with open(trainf, 'r') as f:\n",
    "    cnt_lines = 0\n",
    "    for line in f:\n",
    "        if line == '' or line.strip() == '':\n",
    "            continue\n",
    "        if line[0] in ('#', '%'):\n",
    "            continue\n",
    "        lineparts = line.strip().split(',')\n",
    "        tid = lineparts[0]\n",
    "        mxm_tid = lineparts[1]\n",
    "        for wordcnt in lineparts[2:]:\n",
    "            wordid, cnt = wordcnt.split(':')\n",
    "            q = f\"\"\"\n",
    "            INSERT INTO lyrics\n",
    "            SELECT '{tid}', {mxm_tid}, words.word, {cnt}, 0\n",
    "            FROM words WHERE words.ROWID={wordid}\n",
    "            \"\"\"\n",
    "            conn.execute(q)\n",
    "        cnt_lines += 1\n",
    "        if cnt_lines % 15000 == 0:\n",
    "            print(f'Done with {cnt_lines} train tracks.')\n",
    "            conn.commit()\n",
    "conn.commit()\n",
    "print('Train lyrics added.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77730aba-e144-4ac7-8193-0b17e2fa39ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(testf, 'r') as f:\n",
    "    cnt_lines = 0\n",
    "    for line in f:\n",
    "        if line == '' or line.strip() == '':\n",
    "            continue\n",
    "        if line[0] in ('#', '%'):\n",
    "            continue\n",
    "        lineparts = line.strip().split(',')\n",
    "        tid = lineparts[0]\n",
    "        mxm_tid = lineparts[1]\n",
    "        for wordcnt in lineparts[2:]:\n",
    "            wordid, cnt = wordcnt.split(':')\n",
    "            q = f\"\"\"\n",
    "            INSERT INTO lyrics\n",
    "            SELECT '{tid}', {mxm_tid}, words.word, {cnt}, 1\n",
    "            FROM words WHERE words.ROWID={wordid}\n",
    "            \"\"\"\n",
    "            conn.execute(q)\n",
    "        cnt_lines += 1\n",
    "        if cnt_lines % 15000 == 0:\n",
    "            print(f'Done with {cnt_lines} test tracks.')\n",
    "            conn.commit()\n",
    "conn.commit()\n",
    "print('Test lyrics added.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17b24ec-ae0f-484c-ba5b-285c9f446b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"CREATE INDEX idx_lyrics1 ON lyrics (track_id)\"\n",
    "conn.execute(q)\n",
    "q = \"CREATE INDEX idx_lyrics2 ON lyrics (mxm_tid)\"\n",
    "conn.execute(q)\n",
    "q = \"CREATE INDEX idx_lyrics3 ON lyrics (word)\"\n",
    "conn.execute(q)\n",
    "q = \"CREATE INDEX idx_lyrics4 ON lyrics (count)\"\n",
    "conn.execute(q)\n",
    "q = \"CREATE INDEX idx_lyrics5 ON lyrics (is_test)\"\n",
    "conn.execute(q)\n",
    "conn.commit()\n",
    "print('Indices created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7e4d02-257b-447c-80b1-c5b96dd9dd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()\n",
    "print('Database connection closed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e7be8e-2906-480d-be9b-286040e70f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = \"/Users/vivekrambha/Documents/QMUL Slides and Notes/Music recommendation system/music_recommendation.db\"\n",
    "conn = sqlite3.connect(db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afaf8cc-4eb7-46d6-a600-2ea9b3b54c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query data from the 'words' table\n",
    "words_query = \"SELECT * FROM words\"\n",
    "words_df = pd.read_sql_query(words_query, conn)\n",
    "\n",
    "# Query data from the 'lyrics' table\n",
    "lyrics_query = \"SELECT * FROM lyrics\"\n",
    "lyrics_df = pd.read_sql_query(lyrics_query, conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8a2d2d-88ad-4a2e-8dad-84e6d3d8451c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the 'words' table data to CSV\n",
    "words_csv_path = \"words.csv\"\n",
    "words_df.to_csv(words_csv_path, index=False)\n",
    "\n",
    "# Save the 'lyrics' table data to CSV\n",
    "lyrics_csv_path = \"lyrics.csv\"\n",
    "lyrics_df.to_csv(lyrics_csv_path, index=False)\n",
    "\n",
    "print(\"CSV files created:\")\n",
    "print(f\"- {words_csv_path}\")\n",
    "print(f\"- {lyrics_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9f44bf-1c00-4ef4-9f8c-2c30f645421d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files\n",
    "df1 = pd.read_csv('/Users/vivekrambha/Documents/QMUL Slides and Notes/Music recommendation system/song_features.csv')\n",
    "df2 = pd.read_csv('/Users/vivekrambha/Documents/QMUL Slides and Notes/Music recommendation system/lyrics.csv')\n",
    "df3 = pd.read_csv('/Users/vivekrambha/Documents/QMUL Slides and Notes/Music recommendation system/words.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b67d4b-1f9c-402f-9a3a-d1b3af599302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df1 and df2 on song_id (track_id) and track_id\n",
    "merged_df = pd.merge(df1, df2, left_on='song_id', right_on='track_id')\n",
    "\n",
    "# Merge the resulting DataFrame with df3 on word\n",
    "final_df = pd.merge(merged_df, df3, on='word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0c357e-b018-4b75-9e41-7ee69394e033",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 'combined_data.csv'\n",
    "final_df.to_csv(output_path, index=False)\n",
    "print(f\"Combined CSV file saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
